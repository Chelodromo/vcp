{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2\n",
    "\n",
    "**Objetivo:** Implementar un detector de máximo enfoque sobre un video aplicando técnicas de análisis espectral similar al que utilizan las cámaras digitales modernas. El video a procesar será: \"focus_video.mov\".\n",
    "\n",
    "Se debe implementar un algoritmo que dada una imagen, o región, calcule la métrica propuesta en el paper \"Image Sharpness Measure for Blurred Images in Frequency Domain\" y realizar tres experimentos:\n",
    "\n",
    "1. Medición sobre todo el frame.\n",
    "2. Medición sobre una ROI ubicada en el centro del frame. Area de la ROI = 50 10% del area total del frame.\n",
    "Para cada experimento se debe presentar:\n",
    "\n",
    "Una curva o varias curvas que muestren la evolución de la métrica frame a frame donde se vea claramente cuando el algoritmo detecto el punto de máximo enfoque.\n",
    "El algoritmo de detección a implementar debe detectar y devolver los puntos de máximo enfoque de manera automática.\n",
    "\n",
    "Puntos extra: Aplicar unsharp masking para expandir la zona de enfoque y devolver.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "![image](https://github.com/user-attachments/assets/7b447ea7-95d5-4afb-b770-dc40a2f2a448)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extracción de frames del video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with clang version 18.1.8\n",
      "  configuration: --prefix=/opt/anaconda3/envs/ia_ceia_18co --cc=arm64-apple-darwin20.0.0-clang --cxx=arm64-apple-darwin20.0.0-clang++ --nm=arm64-apple-darwin20.0.0-nm --ar=arm64-apple-darwin20.0.0-ar --disable-doc --enable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-cross-compile --arch=arm64 --target-os=darwin --cross-prefix=arm64-apple-darwin20.0.0- --host-cc=/Users/runner/miniforge3/conda-bld/ffmpeg_1741820504521/_build_env/bin/x86_64-apple-darwin13.4.0-clang --enable-neon --disable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-libopenvino --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libvorbis --enable-libopus --enable-librsvg --enable-ffplay --pkg-config=/Users/runner/miniforge3/conda-bld/ffmpeg_1741820504521/_build_env/bin/pkg-config\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'focus_video.mov':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-06-30T22:16:57.000000Z\n",
      "  Duration: 00:00:05.71, start: 0.000000, bitrate: 2340 kb/s\n",
      "  Stream #0:0[0x1](eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 265 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-06-30T22:16:57.000000Z\n",
      "        handler_name    : Core Media Audio\n",
      "        vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](eng): Video: h264 (Main) (avc1 / 0x31637661), yuvj420p(pc, smpte170m/smpte170m/bt709, progressive), 640x360, 2066 kb/s, 29.97 fps, 29.97 tbr, 30k tbn (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-06-30T22:16:57.000000Z\n",
      "        handler_name    : Core Media Video\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : H.264\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (h264 (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x1501b8000] deprecated pixel format used, make sure you did set range correctly\n",
      "[swscaler @ 0x1501b8000] [swscaler @ 0x1488b8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501b8000] [swscaler @ 0x120108000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501b8000] [swscaler @ 0x120118000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501b8000] [swscaler @ 0x120128000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501b8000] [swscaler @ 0x120138000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501b8000] [swscaler @ 0x120148000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501b8000] [swscaler @ 0x120158000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501b8000] [swscaler @ 0x120168000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501b8000] [swscaler @ 0x120178000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501b8000] [swscaler @ 0x120188000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501b8000] [swscaler @ 0x120198000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501b8000] [swscaler @ 0x1201a8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501b8000] [swscaler @ 0x1201b8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "Output #0, image2, to 'extracted_frames/frame_%04d.png':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    encoder         : Lavf61.7.100\n",
      "  Stream #0:0(eng): Video: png, rgb24(pc, gbr/smpte170m/bt709, progressive), 640x360, q=2-31, 200 kb/s, 1 fps, 1 tbn (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-06-30T22:16:57.000000Z\n",
      "        handler_name    : Core Media Video\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.101 png\n",
      "[out#0/image2 @ 0x13fc193b0] video:1526KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: unknown\n",
      "frame=    6 fps=0.0 q=-0.0 Lsize=N/A time=00:00:06.00 bitrate=N/A speed= 126x    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='ffmpeg -i focus_video.mov -vf fps=1 extracted_frames/frame_%04d.png', returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "video_path = 'focus_video.mov'\n",
    "output_dir = 'extracted_frames'  # Directorio para almacenar los frames\n",
    "os.makedirs(output_dir, exist_ok=True)  # Crear directorio si no existe\n",
    "\n",
    "# Extraer cada 1 frame por segundo usando FFmpeg\n",
    "# %04d crea nombres de archivos de 4 dígitos secuenciales (e.g., frame_0001.png)\n",
    "extract_command = f'ffmpeg -i {video_path} -vf fps=1 {output_dir}/frame_%04d.png'\n",
    "subprocess.run(extract_command, shell=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementación de la métrica de enfoque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_sharpness(input_image):\n",
    "    \"\"\"\n",
    "    Calcula la métrica de nitidez de la imagen basándose en componentes de alta frecuencia en el dominio de Fourier (algoritmo del artículo referenciado).\n",
    "    Argumentos:\n",
    "    input_image(numpy.ndarray): Imagen a color en formato RGB.\n",
    "\n",
    "    Devuelve:\n",
    "    float: Puntuación de nitidez entre 0 (borrosa) y 1 (nítida). / sharpness_score\n",
    "    \"\"\"\n",
    "    # Convertir a escala de grises para el análisis de frecuencias\n",
    "    grayscale_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Fast Fourier Transform (FFT) and shift zero-frequency to center\n",
    "    fourier_transform = np.fft.fft2(grayscale_image)\n",
    "    fourier_shifted = np.fft.fftshift(fourier_transform)\n",
    "    \n",
    "    # Get magnitude spectrum (absolute values)\n",
    "    magnitude_spectrum = np.abs(fourier_shifted)\n",
    "    \n",
    "    # Dynamic threshold calculation (1/1000 of max magnitude)\n",
    "    max_magnitude = np.max(magnitude_spectrum)\n",
    "    high_freq_threshold = max_magnitude / 1000\n",
    "    \n",
    "    # Count high-frequency components above threshold\n",
    "    high_freq_mask = magnitude_spectrum > high_freq_threshold\n",
    "    high_freq_count = np.sum(high_freq_mask)\n",
    "    \n",
    "    # Normalize by total pixels to get sharpness score\n",
    "    total_pixels = grayscale_image.shape[0] * grayscale_image.shape[1]\n",
    "    sharpness_score = high_freq_count / total_pixels\n",
    "    \n",
    "    return sharpness_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiment Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_full_frame(frames_directory):\n",
    "    \"\"\"\n",
    "    Experimento 1: Análisis de nitidez en fotogramas completos de vídeo /Sharpness analysis on full video frames\n",
    "    Argumentos:\n",
    "        frames_directory (str): Ruta a los fotogramas extraídos\n",
    "\n",
    "    Devuelve:\n",
    "        list: Puntuaciones de nitidez de cada fotograma /Sharpness scores for each frame\n",
    "    \"\"\"\n",
    "    frame_scores = []\n",
    "    \n",
    "    for frame_filename in sorted(os.listdir(frames_directory)):\n",
    "        frame_path = os.path.join(frames_directory, frame_filename)\n",
    "        frame_data = cv2.imread(frame_path)\n",
    "        \n",
    "        current_score = calculate_sharpness(frame_data)\n",
    "        frame_scores.append(current_score)\n",
    "    \n",
    "    return frame_scores\n",
    "\n",
    "\n",
    "def process_central_roi(frames_directory):\n",
    "    \"\"\"\n",
    "    Experimento 2: Análisis de nitidez en la región de interés (ROI) central\n",
    "    Tamaño de la ROI = 10 % del área total del fotograma (cuadrado centrado en el fotograma)\n",
    "    Argumentos:\n",
    "        frames_directory (str): Ruta a los fotogramas extraídos\n",
    "\n",
    "    Devuelve:\n",
    "        list: Puntuaciones de nitidez para la ROI de cada fotograma/Sharpness scores for the ROI of each frame\n",
    "    \"\"\"\n",
    "    roi_scores = []\n",
    "    \n",
    "    for frame_filename in sorted(os.listdir(frames_directory)):\n",
    "        frame_path = os.path.join(frames_directory, frame_filename)\n",
    "        frame_data = cv2.imread(frame_path)\n",
    "        \n",
    "        # Calculate ROI dimensions\n",
    "        frame_height, frame_width = frame_data.shape[:2]\n",
    "        frame_area = frame_width * frame_height\n",
    "        roi_side = int(np.sqrt(0.1 * frame_area))  # Square root of 10% area\n",
    "        \n",
    "        # Center coordinates\n",
    "        center_x = frame_width // 2\n",
    "        center_y = frame_height // 2\n",
    "        \n",
    "        # Extract ROI (ensuring within frame boundaries)\n",
    "        roi = frame_data[\n",
    "            max(0, center_y - roi_side):min(frame_height, center_y + roi_side),\n",
    "            max(0, center_x - roi_side):min(frame_width, center_x + roi_side)\n",
    "        ]\n",
    "        \n",
    "        current_score = calculate_sharpness(roi)\n",
    "        roi_scores.append(current_score)\n",
    "    \n",
    "    return roi_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Peak Detection Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sharpness_peaks(sharpness_scores, min_prominence=0.1):\n",
    "    \"\"\"\n",
    "    Identifies frames with maximum sharpness using peak detection\n",
    "    \n",
    "    Args:\n",
    "        sharpness_scores (list): Sequence of sharpness values\n",
    "        min_prominence (float): Minimum peak prominence (sensitivity control)\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Indices of detected peak frames\n",
    "    \"\"\"\n",
    "    peak_indices, _ = find_peaks(sharpness_scores, prominence=min_prominence)\n",
    "    return peak_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sharpness_analysis(full_frame_scores, roi_scores, peak_frames_full, peak_frames_roi):\n",
    "    \"\"\"\n",
    "    Visualizes sharpness trends and detected focus points\n",
    "    \n",
    "    Args:\n",
    "        full_frame_scores (list): Experiment 1 results\n",
    "        roi_scores (list): Experiment 2 results\n",
    "        peak_frames_full (np.ndarray): Full frame peak indices\n",
    "        peak_frames_roi (np.ndarray): ROI peak indices\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    # Plot both datasets\n",
    "    plt.plot(full_frame_scores, label='Full Frame Analysis', color='blue', alpha=0.7)\n",
    "    plt.plot(roi_scores, label='Central ROI Analysis', color='green', alpha=0.7)\n",
    "    \n",
    "    # Mark detected peaks\n",
    "    plt.scatter(peak_frames_full, [full_frame_scores[i] for i in peak_frames_full],\n",
    "                color='red', marker='X', s=100, label='Full Frame Peaks')\n",
    "    plt.scatter(peak_frames_roi, [roi_scores[i] for i in peak_frames_roi],\n",
    "                color='purple', marker='D', s=80, label='ROI Peaks')\n",
    "    \n",
    " # Formatting\n",
    "    plt.title('Video Focus Analysis Comparison\\n(Frame-by-Frame Sharpness Measurement)', pad=20)\n",
    "    plt.xlabel('Frame Number', labelpad=15)\n",
    "    plt.ylabel('Sharpness Score', labelpad=15)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Execution Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Process video frames\n",
    "    full_scores = process_full_frame(output_dir)\n",
    "    roi_scores = process_central_roi(output_dir)\n",
    "    \n",
    "    # Detect focus points\n",
    "    full_peaks = detect_sharpness_peaks(full_scores)\n",
    "    roi_peaks = detect_sharpness_peaks(roi_scores)\n",
    "    \n",
    "    # Generate visualization\n",
    "    plot_sharpness_analysis(full_scores, roi_scores, full_peaks, roi_peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_ceia_18co",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
