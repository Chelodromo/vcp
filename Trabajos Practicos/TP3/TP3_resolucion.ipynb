{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version de OpenCV: 4.7.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "#%matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "print(f'Version de OpenCV: {cv.__version__}')\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2\n",
    "\n",
    "(4 puntos) Plantear y validar un algoritmo para múltiples detecciones en la imagen coca multi.png con el mismo témplate del item 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar imagen y template\n",
    "img2_color = cv.imread('./images/coca_multi.png')\n",
    "img2_gray = cv.cvtColor(img2_color, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "img1 = cv.imread('./template/pattern.png', 0)  # Template original\n",
    "img1 = cv.resize(img1, (0, 0), fx=0.5, fy=0.5, interpolation=cv.INTER_AREA)\n",
    "\n",
    "# Aplicar suavizado gaussiano\n",
    "img1 = cv.GaussianBlur(img1, (3, 3), 0)\n",
    "img2 = cv.GaussianBlur(img2_gray, (3, 3), 0)\n",
    "\n",
    "# Aplicar Canny luego del suavizado\n",
    "#img1 = cv.Canny(img1, 200, 200)\n",
    "img2 = cv.Canny(img2, 200, 200)\n",
    "img1 = 255 - img1.copy() \n",
    "# Mostrar resultados finales\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img1, cmap='gray')\n",
    "plt.title(\"Template (Gaussian + Canny)\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(img2, cmap='gray')\n",
    "plt.title(\"Imagen (Gaussian + Canny)\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "# Creamos el vector de características SIFT\n",
    "\n",
    "sift = cv.xfeatures2d.SIFT_create(nfeatures=5000, contrastThreshold=0.01)\n",
    "\n",
    "\n",
    "# Y buscamos según el algoritmo...\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "print(len(kp1))\n",
    "print(len(kp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x287cb24d180>, None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parámetros FLANN\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 150)\n",
    "search_params = dict(checks=200)   # o pasar un diccionario vacío\n",
    "flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "# K es la cantidad de \"best matches\" para cada descriptor\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Necesidad de dibujar solo las coincidencias buenas, se crea una máscara\n",
    "matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "# Ratio de verificación como figura en el paper de Lowe\n",
    "for i,(m,n) in enumerate(matches):\n",
    "    if m.distance < 0.85*n.distance:\n",
    "        matchesMask[i]=[1,0]\n",
    "draw_params = dict(matchColor = (0,255,0),\n",
    "                   singlePointColor = (255,0,0),\n",
    "                   matchesMask = matchesMask,\n",
    "                   flags = cv.DrawMatchesFlags_DEFAULT)\n",
    "img3 = cv.drawMatchesKnn(img1,kp1,img2,kp2,matches,None,**draw_params)\n",
    "plt.imshow(img3,),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 100)\n",
    "search_params = dict(checks = 50)\n",
    "flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "# Guardar todos las buenas coincidencias según la verificación de Ratio de Lowe\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.85*n.distance:\n",
    "        good.append(m)\n",
    "print(len(good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "MIN_MATCH_COUNT = 3\n",
    "\n",
    "if len(good) > MIN_MATCH_COUNT:\n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 1.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "    h,w = img1.shape\n",
    "    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "    dst = cv.perspectiveTransform(pts, M)\n",
    "    img2 = cv.polylines(img2, [np.int32(dst)], True, 255, 3, cv.LINE_AA)\n",
    "else:\n",
    "    print( \"No se encontraron suficientes coincidencias - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "    matchesMask = None\n",
    "\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x287d356d030>, None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_params = dict(matchColor = (0,255,0), # dibujar coincidencias en verde\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # dibujar solo inliers\n",
    "                   flags = 2)\n",
    "img3 = cv.drawMatches(img1, kp1, img2, kp2, good, None, **draw_params)\n",
    "plt.imshow(img3, 'gray'),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unificacion del codigo y ajustes de parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints en el template: 74\n",
      "Keypoints en la imagen destino: 5000\n",
      "Número de good matches: 23\n",
      "Número de clusters encontrados (excluyendo ruido): 2\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. CARGA DEL TEMPLATE Y PREPROCESAMIENTO\n",
    "# ============================================================\n",
    "\n",
    "template_path = './template/pattern.png'  # Ruta del template\n",
    "img_template = cv.imread(template_path, 0)  # Cargar el template en escala de grises\n",
    "if img_template is None:\n",
    "    raise IOError(\"No se pudo cargar el template: \" + template_path)\n",
    "\n",
    "# Redimensionar el template (ajusta fx y fy según convenga)\n",
    "img_template = cv.resize(img_template, (0, 0), fx=0.23, fy=0.23, interpolation=cv.INTER_AREA)\n",
    "# Suavizar el template para reducir ruido\n",
    "img_template = cv.GaussianBlur(img_template, (3, 3), 0)\n",
    "# Invertir el template (opcional; en algunos casos mejora la detección)\n",
    "img_template = 255 - img_template.copy()\n",
    "\n",
    "# ============================================================\n",
    "# 2. CONFIGURACIÓN DE SIFT CON PARÁMETROS AJUSTADOS\n",
    "# ============================================================\n",
    "# IMPORTANTE: Debes tener instalado \"opencv-contrib-python\" para usar cv.xfeatures2d.SIFT_create()\n",
    "sift = cv.xfeatures2d.SIFT_create(nfeatures=5000, contrastThreshold=0.001)\n",
    "# --> Parámetros: \n",
    "#     nfeatures=5000 (máximo número de keypoints a detectar)\n",
    "#     contrastThreshold=0.01 (valores más bajos detectan más keypoints en zonas con poco contraste)\n",
    "\n",
    "# ============================================================\n",
    "# 3. CARGAR LA IMAGEN DESTINO (donde se buscan múltiples logos)\n",
    "# ============================================================\n",
    "img_path = './images/coca_multi.png'\n",
    "img_color = cv.imread(img_path)\n",
    "if img_color is None:\n",
    "    raise IOError(\"No se pudo cargar la imagen: \" + img_path)\n",
    "img_gray = cv.cvtColor(img_color, cv.COLOR_BGR2GRAY)\n",
    "# Suavizar la imagen destino para reducir el ruido\n",
    "img_proc = cv.GaussianBlur(img_gray, (3, 3), 0)\n",
    "\n",
    "# ============================================================\n",
    "# 4. EXTRACCIÓN DE KEYPOINTS Y MATCHING CON FLANN\n",
    "# ============================================================\n",
    "# Extraer características del template y de la imagen destino\n",
    "kp_template, des_template = sift.detectAndCompute(img_template, None)\n",
    "kp_img, des_img = sift.detectAndCompute(img_proc, None)\n",
    "print(\"Keypoints en el template:\", len(kp_template))\n",
    "print(\"Keypoints en la imagen destino:\", len(kp_img))\n",
    "\n",
    "# Configurar FLANN\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=300)  # Ajusta 'trees' para más precisión (150 aquí)\n",
    "search_params = dict(checks=300)  # 'checks' determina cuántas veces se profundiza en la búsqueda\n",
    "flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# Realizar knnMatch (k=2 para aplicar el Ratio Test)\n",
    "matches = flann.knnMatch(des_template, des_img, k=2)\n",
    "\n",
    "# Aplicar Ratio Test de Lowe para filtrar buenos matches (valor 0.9 es ajustable)\n",
    "good_matches = [m for m, n in matches if m.distance < 0.9 * n.distance]\n",
    "print(\"Número de good matches:\", len(good_matches))\n",
    "\n",
    "# ============================================================\n",
    "# 5. CLUSTERIZACIÓN DE LOS MATCHES EN LA IMAGEN DESTINO USANDO DBSCAN\n",
    "# ============================================================\n",
    "# Obtén las coordenadas destino de cada good match\n",
    "dst_coords = np.array([kp_img[m.trainIdx].pt for m in good_matches])\n",
    "# Parámetros de DBSCAN: eps (distancia máxima para considerar vecinos) y min_samples (mínimo número de puntos por cluster)\n",
    "# Ajusta estos valores según la densidad de los matches en tu imagen\n",
    "dbscan = DBSCAN(eps=40, min_samples=3)  # eps=30 píxeles, min_samples=3\n",
    "if len(dst_coords) > 0:\n",
    "    clusters = dbscan.fit_predict(dst_coords)\n",
    "else:\n",
    "    clusters = np.array([])\n",
    "\n",
    "print(\"Número de clusters encontrados (excluyendo ruido):\", len(set(clusters)) - (1 if -1 in clusters else 0))\n",
    "\n",
    "# ============================================================\n",
    "# 6. PARA CADA CLUSTER, CALCULAR HOMOGRAFÍA Y DIBUJAR UN RECUADRO\n",
    "# ============================================================\n",
    "img_final = img_color.copy()\n",
    "\n",
    "# Recorre cada cluster (ignora el ruido, que DBSCAN marca con -1)\n",
    "unique_labels = set(clusters)\n",
    "for label in unique_labels:\n",
    "    if label == -1:\n",
    "        continue  # Saltamos el ruido\n",
    "    # Índices de matches en este cluster\n",
    "    indices = np.where(clusters == label)[0]\n",
    "    # Solo consideramos el cluster si tiene suficiente número de good matches\n",
    "    if len(indices) < 4:  # Ahora usamos 4, ya que findHomography requiere al menos 4 puntos\n",
    "        continue\n",
    "    \n",
    "    # Extraer los matches que pertenecen a este cluster\n",
    "    cluster_matches = [good_matches[i] for i in indices]\n",
    "    # Verificar nuevamente\n",
    "    if len(cluster_matches) < 4:\n",
    "        continue\n",
    "    \n",
    "    # Extraer los puntos del template (origen) y destino (imagen) para los matches del cluster\n",
    "    src_pts = np.float32([kp_template[m.queryIdx].pt for m in cluster_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp_img[m.trainIdx].pt for m in cluster_matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # Calcular la homografía para este cluster usando RANSAC (umbral 1.0, ajustable)\n",
    "    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 4.0)\n",
    "    if M is None:\n",
    "        continue\n",
    "    h, w = img_template.shape  # Dimensiones del template\n",
    "    pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "    dst = cv.perspectiveTransform(pts, M)\n",
    "    # Dibujar el recuadro (polilínea) sobre la imagen final\n",
    "    img_final = cv.polylines(img_final, [np.int32(dst)], True, (0, 255, 0), 3, cv.LINE_AA)\n",
    "\n",
    "# ============================================================\n",
    "# 7. MOSTRAR LA IMAGEN FINAL CON TODOS LOS RECUADROS DETECTADOS\n",
    "# ============================================================\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(cv.cvtColor(img_final, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Detección múltiple de logos (clusters)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se detectaron 8 botellas de Coca-Cola\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    boxes = boxes.astype(\"float\")\n",
    "    pick = []\n",
    "\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "\n",
    "    while len(idxs) > 0:\n",
    "        last = idxs[-1]\n",
    "        pick.append(last)\n",
    "\n",
    "        xx1 = np.maximum(x1[last], x1[idxs[:-1]])\n",
    "        yy1 = np.maximum(y1[last], y1[idxs[:-1]])\n",
    "        xx2 = np.minimum(x2[last], x2[idxs[:-1]])\n",
    "        yy2 = np.minimum(y2[last], y2[idxs[:-1]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        overlap = (w * h) / area[idxs[:-1]]\n",
    "        idxs = np.delete(idxs, np.concatenate(([len(idxs) - 1], np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    return boxes[pick].astype(\"int\")\n",
    "\n",
    "def detect_coca_cola_bottles(img_path, template_path):\n",
    "    # Cargar las imágenes\n",
    "    img = cv.imread(img_path)\n",
    "    template = cv.imread(template_path)\n",
    "    \n",
    "    # Convertir a escala de grises\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    template_gray = cv.cvtColor(template, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Aplicar detección de bordes Canny al patrón\n",
    "    template_edges = cv.Canny(template_gray, 50, 150)\n",
    "    \n",
    "    # Escalar el patrón a un tamaño fijo (0.2 del original)\n",
    "    scale_width = 0.2\n",
    "    scale_height = 0.2\n",
    "    width = int(template_edges.shape[1] * scale_width)\n",
    "    height = int(template_edges.shape[0] * scale_height)\n",
    "    resized_template = cv.resize(template_edges, (width, height))\n",
    "    \n",
    "    # Aplicar Canny a la imagen de entrada\n",
    "    img_edges = cv.Canny(img_gray, 150, 150)\n",
    "    \n",
    "    # Obtener dimensiones del template\n",
    "    h, w = resized_template.shape\n",
    "    \n",
    "    # Aplicar template matching\n",
    "    result = cv.matchTemplate(img_edges, resized_template, cv.TM_CCORR_NORMED)\n",
    "    \n",
    "    # Umbral de detección\n",
    "    threshold = 0.22\n",
    "    locations = np.where(result >= threshold)\n",
    "    \n",
    "    # Crear lista de cajas para aplicar NMS\n",
    "    rects = []\n",
    "    for pt in zip(*locations[::-1]):\n",
    "        rects.append([pt[0], pt[1], pt[0] + w, pt[1] + h])\n",
    "    \n",
    "    rects = np.array(rects)\n",
    "    final_boxes = non_max_suppression_fast(rects, 0.3)  # umbral de solapamiento\n",
    "    \n",
    "    # Dibujar cajas resultantes\n",
    "    img_result = img.copy()\n",
    "    for (x1, y1, x2, y2) in final_boxes:\n",
    "        cv.rectangle(img_result, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    # Mostrar resultado\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv.cvtColor(img_result, cv.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Método: TM_CCORR_NORMED con Canny\\nDetecciones únicas: {len(final_boxes)}\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return len(final_boxes), img_result\n",
    "\n",
    "detections_count, result_img = detect_coca_cola_bottles('images/coca_multi.png', 'template/pattern.png')\n",
    "print(f\"Se detectaron {detections_count} botellas de Coca-Cola\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando: ./images\\COCA-COLA-LOGO.jpg\n",
      "  Keypoints - Template: 74 | Imagen: 3879\n",
      "  Good matches: 26\n",
      "  Número de clusters (instancias): 22\n",
      "Procesando: ./images\\coca_logo_1.png\n",
      "  Keypoints - Template: 74 | Imagen: 652\n",
      "  Good matches: 45\n",
      "  Número de clusters (instancias): 2\n",
      "Procesando: ./images\\coca_logo_2.png\n",
      "  Keypoints - Template: 74 | Imagen: 726\n",
      "  Good matches: 32\n",
      "  Número de clusters (instancias): 4\n",
      "Procesando: ./images\\coca_multi.png\n",
      "  Keypoints - Template: 74 | Imagen: 5000\n",
      "  Good matches: 23\n",
      "  Número de clusters (instancias): 13\n",
      "Procesando: ./images\\coca_retro_1.png\n",
      "  Keypoints - Template: 74 | Imagen: 5000\n",
      "  Good matches: 11\n",
      "  Número de clusters (instancias): 10\n",
      "Procesando: ./images\\coca_retro_2.png\n",
      "  Keypoints - Template: 74 | Imagen: 1862\n",
      "  Good matches: 32\n",
      "  Número de clusters (instancias): 5\n",
      "Procesando: ./images\\logo_1.png\n",
      "  Keypoints - Template: 74 | Imagen: 776\n",
      "  Good matches: 28\n",
      "  Número de clusters (instancias): 7\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# ============================================================\n",
    "# 1. CARGA DEL TEMPLATE Y PREPROCESAMIENTO\n",
    "# ============================================================\n",
    "template_path = './template/pattern.png'  # Ruta del template\n",
    "img_template = cv.imread(template_path, 0)  # Cargar el template en escala de grises\n",
    "if img_template is None:\n",
    "    raise IOError(\"No se pudo cargar el template: \" + template_path)\n",
    "\n",
    "# Redimensionar el template (ajusta fx y fy según convenga)\n",
    "img_template = cv.resize(img_template, (0, 0), fx=0.23, fy=0.23, interpolation=cv.INTER_AREA)\n",
    "# Suavizar el template para reducir ruido\n",
    "img_template = cv.GaussianBlur(img_template, (3, 3), 0)\n",
    "# Invertir el template (opcional; en algunos casos mejora la detección)\n",
    "img_template = 255 - img_template.copy()\n",
    "\n",
    "# ============================================================\n",
    "# 2. CONFIGURACIÓN DE SIFT CON PARÁMETROS AJUSTADOS\n",
    "# ============================================================\n",
    "# IMPORTANTE: Debes tener instalado \"opencv-contrib-python\" para usar cv.xfeatures2d.SIFT_create()\n",
    "sift = cv.xfeatures2d.SIFT_create(nfeatures=5000, contrastThreshold=0.01)\n",
    "# nfeatures=5000 -> Máximo número de keypoints a detectar.\n",
    "# contrastThreshold=0.01 -> Umbral de contraste (valores menores detectan más puntos).\n",
    "\n",
    "# ============================================================\n",
    "# 3. OBTENER LA LISTA DE IMÁGENES EN LA CARPETA \"images\"\n",
    "# ============================================================\n",
    "image_files = glob.glob(os.path.join('./images', '*.jpg')) + glob.glob(os.path.join('./images', '*.png'))\n",
    "if not image_files:\n",
    "    raise IOError(\"No se encontraron imágenes en la carpeta 'images'.\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. PROCESAR CADA IMAGEN\n",
    "# ============================================================\n",
    "for img_path in image_files:\n",
    "    print(\"Procesando:\", img_path)\n",
    "    # Cargar la imagen destino en color y obtener su versión en escala de grises\n",
    "    img_color = cv.imread(img_path)\n",
    "    if img_color is None:\n",
    "        print(\"No se pudo cargar:\", img_path)\n",
    "        continue\n",
    "    img_gray = cv.cvtColor(img_color, cv.COLOR_BGR2GRAY)\n",
    "    # Suavizar la imagen destino para reducir ruido\n",
    "    img_proc = cv.GaussianBlur(img_gray, (3, 3), 0)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 5. EXTRAER KEYPOINTS Y DESCRIPTORES CON SIFT PARA TEMPLATE E IMAGEN DESTINO\n",
    "    # ============================================================\n",
    "    kp_template, des_template = sift.detectAndCompute(img_template, None)\n",
    "    kp_img, des_img = sift.detectAndCompute(img_proc, None)\n",
    "    print(\"  Keypoints - Template:\", len(kp_template), \"| Imagen:\", len(kp_img))\n",
    "    \n",
    "    # ============================================================\n",
    "    # 6. MATCHING CON FLANN Y RATIO TEST\n",
    "    # ============================================================\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=300)  # Aumenta 'trees' para mayor precisión\n",
    "    search_params = dict(checks=300)  # Mayor número de 'checks' para exactitud\n",
    "    flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des_template, des_img, k=2)\n",
    "    # Filtrar buenos matches usando Ratio Test (ajustable, aquí 0.9)\n",
    "    good_matches = [m for m, n in matches if m.distance < 0.9 * n.distance]\n",
    "    print(\"  Good matches:\", len(good_matches))\n",
    "    \n",
    "    # ============================================================\n",
    "    # 7. CLUSTERIZACIÓN DE LOS MATCHES CON DBSCAN\n",
    "    # ============================================================\n",
    "    # Obtener las coordenadas destino de cada good match\n",
    "    dst_coords = np.array([kp_img[m.trainIdx].pt for m in good_matches])\n",
    "    # Parámetros para DBSCAN:\n",
    "    # - eps: distancia máxima (en píxeles) para considerar puntos vecinos.\n",
    "    # - min_samples: mínimo número de puntos para formar un cluster.\n",
    "    dbscan = DBSCAN(eps=50, min_samples=1)  # Ajusta 'eps' si se da un logo muy grande o pequeño.\n",
    "    clusters = dbscan.fit_predict(dst_coords) if len(dst_coords) > 0 else np.array([])\n",
    "    \n",
    "    num_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)\n",
    "    print(\"  Número de clusters (instancias):\", num_clusters)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 8. PARA CADA CLUSTER, CALCULAR HOMOGRAFÍA, DIBUJAR BOUNDING BOX Y MOSTRAR CONFIDENCIA\n",
    "    # ============================================================\n",
    "    img_final = img_color.copy()\n",
    "    unique_labels = set(clusters)\n",
    "    for label in unique_labels:\n",
    "        if label == -1:  # DBSCAN marca con -1 el ruido\n",
    "            continue\n",
    "        # Obtén los índices de los matches en este cluster\n",
    "        indices = np.where(clusters == label)[0]\n",
    "        # Requerir al menos 4 matches para poder calcular homografía\n",
    "        if len(indices) < 4:\n",
    "            continue\n",
    "        cluster_matches = [good_matches[i] for i in indices]\n",
    "        # Extraer puntos correspondientes del template y de la imagen destino\n",
    "        src_pts = np.float32([kp_template[m.queryIdx].pt for m in cluster_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp_img[m.trainIdx].pt for m in cluster_matches]).reshape(-1, 1, 2)\n",
    "        \n",
    "        # Calcular homografía usando RANSAC. El umbral 1.0 es ajustable.\n",
    "        M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 1.0)\n",
    "        if M is None:\n",
    "            continue\n",
    "        # Calcular nivel de confianza como la proporción de inliers\n",
    "        inliers_ratio = float(np.sum(mask)) / float(len(mask))\n",
    "        \n",
    "        h, w = img_template.shape  # Dimensiones del template\n",
    "        pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "        dst_box = cv.perspectiveTransform(pts, M)\n",
    "        \n",
    "        # Dibujar el bounding box (recuadro) sobre la imagen destino\n",
    "        img_final = cv.polylines(img_final, [np.int32(dst_box)], True, (0, 255, 0), 3, cv.LINE_AA)\n",
    "        # Obtener la esquina superior izquierda del recuadro para colocar el texto\n",
    "        top_left = tuple(np.int32(dst_box[0][0]))\n",
    "        # Escribir el nivel de confianza (porcentaje de inliers)\n",
    "        cv.putText(img_final, f\"{inliers_ratio*100:.1f}%\", top_left, cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 9. MOSTRAR LA IMAGEN FINAL CON TODOS LOS BOUNDING BOXES Y CONFIDENCIA\n",
    "    # ============================================================\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.imshow(cv.cvtColor(img_final, cv.COLOR_BGR2RGB))\n",
    "    plt.title(\"Detección múltiple de logos con bounding boxes y confianza\\n\" + os.path.basename(img_path))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def detectar_multiples_coca_logos():\n",
    "    template_path = './template/pattern.png'\n",
    "    image_path = './images/coca_multi.png'\n",
    "\n",
    "    # Cargar imágenes\n",
    "    img2_color = cv.imread(image_path)\n",
    "    img2_gray = cv.cvtColor(img2_color, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    img1 = cv.imread(template_path, 0)  # Template original\n",
    "    img1 = cv.resize(img1, (0, 0), fx=0.4, fy=0.4, interpolation=cv.INTER_AREA)\n",
    "\n",
    "    # Aplicar suavizado gaussiano\n",
    "    img1 = cv.GaussianBlur(img1, (3, 3), 0)\n",
    "    img2 = cv.GaussianBlur(img2_gray, (3, 3), 0)\n",
    "\n",
    "    # Aplicar Canny a la imagen general (no al template)\n",
    "    img2_trabajo = cv.Canny(img2, 200, 200)\n",
    "\n",
    "    # Invertir template\n",
    "    img1 = 255 - img1.copy()\n",
    "\n",
    "    # Inicializar resultado final\n",
    "    resultado = img2_color.copy()\n",
    "\n",
    "    # Detectores\n",
    "    sift = cv.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    bf = cv.BFMatcher()\n",
    "\n",
    "    print(f\"Keypoints en template: {len(kp1)}\")\n",
    "\n",
    "    detecciones = 0\n",
    "    MAX_ITERACIONES = 300\n",
    "\n",
    "    for i in range(MAX_ITERACIONES):\n",
    "        kp2, des2 = sift.detectAndCompute(img2_trabajo, None)\n",
    "        if des2 is None or len(kp2) < 1:\n",
    "            break\n",
    "\n",
    "        matches = bf.knnMatch(des1, des2, k=2)\n",
    "        good = [m for m, n in matches if m.distance < 0.8 * n.distance]\n",
    "\n",
    "        print(f\"Iteración {i+1}: {len(good)} good matches\")\n",
    "\n",
    "        if len(good) < 4:\n",
    "            break\n",
    "\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "        M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 3.0)\n",
    "        inliers = np.sum(mask) if mask is not None else 0\n",
    "\n",
    "        if M is not None and inliers >= 2:\n",
    "            h, w = img1.shape\n",
    "            box = np.float32([[0,0], [0,h], [w,h], [w,0]]).reshape(-1, 1, 2)\n",
    "            dst = cv.perspectiveTransform(box, M)\n",
    "\n",
    "            area = cv.contourArea(np.int32(dst))\n",
    "            if area < 1000:\n",
    "                print(f\"Área muy pequeña: {area}\")\n",
    "                break\n",
    "\n",
    "            resultado = cv.polylines(resultado, [np.int32(dst)], True, (0, 255, 0), 3, cv.LINE_AA)\n",
    "\n",
    "            mask_poly = np.zeros_like(img2_trabajo)\n",
    "            cv.fillPoly(mask_poly, [np.int32(dst)], 255)\n",
    "            mask_poly = cv.dilate(mask_poly, np.ones((7, 7), np.uint8), iterations=1)\n",
    "            img2_trabajo = cv.inpaint(img2_trabajo, mask_poly, 3, cv.INPAINT_TELEA)\n",
    "\n",
    "            detecciones += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(f\"Detecciones totales: {detecciones}\")\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv.cvtColor(resultado, cv.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Detecciones proyectadas de logos (total: {detecciones})\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return detecciones, resultado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints en template: 94\n",
      "Iteración 1: 0 good matches\n",
      "Detecciones totales: 0\n",
      "Imagen guardada con 0 detecciones.\n"
     ]
    }
   ],
   "source": [
    "detecciones, resultado = detectar_multiples_coca_logos()\n",
    "cv.imwrite('resultado_coca_detecciones.png', resultado)\n",
    "print(f\"Imagen guardada con {detecciones} detecciones.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
